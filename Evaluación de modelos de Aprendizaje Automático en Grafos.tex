\documentclass[conference,a4paper]{IEEEtran}

% Escritura mejorada de fórmulas matemáticas
\usepackage{amsmath}

% Inserción de gráficos
\usepackage{graphicx}

% Escritura de pseudocódigo
\usepackage[kw]{pseudo}

% Escritura mejorada de tablas
\usepackage{booktabs}

% Escritura mejorada de citas bibliográficas
\usepackage{cite}

% Hacer hipervínculos
\usepackage{hyperref}

% Para la funcion indicador
\usepackage{bbm}

% Símbolos matemticos
\usepackage{mathrsfs}

% Macros traducidas
\def\contentsname{Índice general}
\def\listfigurename{Índice de figuras}
\def\listtablename{Índice de tablas}
\def\refname{Referencias}
\def\indexname{Índice alfabético}
\def\figurename{Fig.}
\def\tablename{TABLA}
\def\partname{Parte}
\def\appendixname{Apéndice}
\def\abstractname{Resumen}
% IEEE specific names
\def\IEEEkeywordsname{Palabras clave}
\def\IEEEproofname{Demostración}


\begin{document}

\title{Evaluación de modelos de Aprendizaje Automático en Grafos}

\author{
  \IEEEauthorblockN{Domínguez-Adame Ruiz, Alberto}
  \IEEEauthorblockA{
    \textit{Dpto. Ciencias de la Computación e Inteligencia Artificial}\\
    \textit{Universidad de Sevilla}\\
    Sevilla, España\\
     albdomrui@alum.us.es}
  
  \and
  
  \IEEEauthorblockN{Vilaplana de Trias, Francisco David}
  \IEEEauthorblockA{
    \textit{Dpto. Ciencias de la Computación e Inteligencia Artificial}\\
    \textit{Universidad de Sevilla}\\
    Sevilla, España\\
   fravilde1@alum.us.es}
}

\maketitle


% Resumen
\begin{abstract}

  El objetivo principal de este trabajo es diseñar y evaluar distintos modelos de aprendizaje automático       relacional para clasificar los nodos de un grafo a partir de sus propiedades, y ver como interactua el modelo  antes y después de introducir los atributos relacionales. 
  Para este fin, hemos realizado cuatro modelos diferentes: KNN, Naive Bayes, Árbol de Decisión y Redes Neuronales. Primeramente construimos el modelo, lo entrenamos y lo evaluamos, todo esto sin atributos relacionales. Seguidamente se calculan los atributos relacionales, en nuestro caso Centralidad de intermediación, agrupamiento (clustering) y grado (Degree). A continuación repetimos los pasos después de añadir los atriutos relacionales a el conjunto de datos. Finalmente comparamos los resultados relacionales con los no relacionales para concluir si los atributos relacionales mejoran o no el rendimiento de los modelos, y entonces elegiremos el modelo que nos haya proporcionado mejores resultados  en general (relacionales y no relacionales).

\end{abstract}


% Palabras claves
\begin{IEEEkeywords}
  Inteligencia Artificial, KNN, Naive Bayes, Árbol de Decisión, Redes Neuronales, Aprendizaje Automático Relacional...
\end{IEEEkeywords}


\section{Introducción}


Para empezar, el aprendizaje se define como la adquisición del conocimiento de algo por medio del estudio, el ejercicio o la experiencia, en especial de los conocimientos necesarios para aprender algún arte u oficio. Al hablar sobre el aprendizaje automático estaríamos entrando en el campo de la Inteligencia Artificial (IA). Podemos definir esta como un programa de computación diseñado para realizar determinadas operaciones que se consideran propias de la inteligencia humana, como el Aprendizaje Automático (Machine Learning), una rama de la inteligencia artificial, cuyo objetivo es el desarrollo de un sistema (modelo matemático que realiza una determinada tarea)  el cual tiene un mejor desempeño con la experiencia, dados una serie de datos.

Nuestro estudio hace uso de datos relacionales, los cuales están unidos entre sí (tienen una relación) que queda representado como aristas en un grafo, entendiendo un grafo como un conjunto de nodos unido (o no) mediante aristas. En la Fig. \ref{fig:tablaEj} podemos ver un ejemplo de un grafo a partir de unos datos relacionales. 

\begin{figure} % opción de posicionamiento
    \centering
    \includegraphics[width=0.4\textwidth]{./ImagenesMemoria/TablaEjemplo}
    \caption{\label{fig:tablaEj}Ejemplo de Grafo}
\end{figure}


Para la realización de este trabajo se ha hecho uso del entorno de desarrollo Jupyter y de la herramienta notebook. El código está escrito mediante el lenguaje de programación Python, usando principalmente las librerías pandas, NetworkX y scikit-learn, y otras como keras, tensorflow y matplot.



Los modelos de clasificación usados son: KNN, Naive Bayes, Árboles de Decisión y Redes Neuronales.

\section{Conjunto de datos y Tarea de predicción a realizar}
Hemos elegido un dataset (fíjese en la Fig. \ref{fig:dataset}) de la página de streamings en directo twitch.tv, en la que se ve: las visitas, días (ambos de tipo entero) que transmitido un canal en directo, si tiene contrato o no con twitch (partner de tipo Boolean) y si el contenido del canal (id de tipo Integer) es o no para adultos (mature de tipo Boolean). Al ser la propia Twitch la que ofrece este contrato, hemos decidido que la predicción para nuestros modelos sea el atributo partner (true/false). Las aristas (edges) representan si dos usuarios tienen una relación de amistad.

\begin{figure} % opción de posicionamiento
    \centering
    \includegraphics[width=0.3\textwidth]{./ImagenesMemoria/dataset}
    \caption{\label{fig:dataset}Tabla de Datos}
\end{figure}

Este dataset tenía dos tipos de id asociados a cada usuario, uno generado aleatoriamente y otro donde al usuario se le asignaba un valor entre 0 y el numero total de usuarios que recoge el conjunto de datos, por lo que decidimos que eliminar el id generado de forma aleatoria para mayor claridad y sólo hace falta un id por usuario para identificarlos.


Para este estudio hemos decidido que el atributo a predecir será partner. Para ello, haremos uso de los atributos: days, views y mature (el id no es relevante en este caso). Lo hemos planteado como una tarea de clasificación binaria, ya que partner solo tiene dos valores posibles (True o False).

 Por último hemos codificado (codificación one-hot) los valores de mature de Booleano a Integer, pasando True-False a 1-0 respectivamente, para que sea más eficiente estimar las probabilidades del atributo partner.

\section{Métricas Relacionales}
Como este es un trabajo de desarrollo de modelos orientados al aprendizaje automático grafos, hemos elegido una serie de métricas relacionales que aplicaremos como atributos relacionales. En concreto hemos elgido tres métricas:

\begin{enumerate}
\item\textbf{Betweenness centrality} (Centralidad de intermediación): La centralidad en un grafo puede ser entendida como una medida que determina la relevancia de un nodo dentro del grafo y permite comparar o contrastar dicho vértice con otros. La Betweenness Centrality es una medida de centralidad que cuantifica la frecuencia en la que un nodo se encuentra en el camino más corto entre dos nodos determinados. Cuando en un grafo existen nodos de alta intermediación, estos suelen jugar un rol importante en la estructura a la que pertenecen. Estos nodos también poseen capacidades de ser controladores o reguladores de los flujos de información dentro de la estructura total del grafo. 
\item\textbf{Clustering} (agrupamiento): es una tarea que tiene como finalidad principal lograr el agrupamiento de nodos, para lograr construir subconjuntos de datos conocidos como Clusters.
\item\textbf{Degree} (grado): Número de aristas (relaciones) que inciden sobre el nodo.
\end{enumerate}


 
\section{Algoritmos de Aprendizaje Automático}
A continuación exponemos los algoritmos que hemos utilizado con nuestro dataset:

\begin{figure} % opción de posicionamiento
    \centering
    \includegraphics[width=0.4\textwidth]{./ImagenesMemoria/TablaRelacional}
    \caption{\label{fig:datasetRelacional}Tabla de Datos Relacional}
\end{figure}

\subsection{KNN}
El algoritmo kNN (del inglés \emph{k Nearest Neighbors}, k vecinos más cercanos), es un clasificador de aprendizaje supervisado no paramétrico, por lo que la cantidad de parámetros del modelo coincide exactamente con la cantidad de ejemplos de entrenamiento. Se basa en la proximidad de los k nodos más cercanos calculando la cercanía a partir de los atributos, si estos fueran discretos sería necesaria una codificación de los mismo. 

Analizando nuestro dataset, se puede observar como el atributo "\emph{views}" toma valores de mayor magnitud con respecto al resto lo que provoca que tenga más en cuenta para la predicción del modelo. Con el fin de evitar esta situación se hace uso de la normalización a los atributos del conjunto de entrenamiento. Existe una gran variedad de maneras de normalizar un atributo numérico, nosotros hemos optado por el método min-max \cite{b1} que consiste en que a cada atributo restarle el valor mínimo de este y dividir esta diferencia entre la resta del valor máximo y mínimo: 

\begin{equation}
v_{i}' = \frac{v_{i} - m}{M - m}
\end{equation}

Para realizar kNN es necesario dar un valor al hiperparámetro k, referido al número de vecinos que se va a tener en cuenta a la hora de clasificar un nuevo dato, nosotros le hemos dado valores del uno al diez para más tarde evaluar el rendimiento de cada uno y elegir el mejor. También existen métodos para calcular la distancia, en nuestro caso hemos usado:
\begin{itemize}
\item Distancia de \emph{Hamming} para el dataset sin atributos relacionales:
\begin{equation}
d(\textbf{x},\textbf{x}') = \sum_{i=1}^n \mathbbm{1}{(x_{i}\neq{x_{i}'})}
\end{equation}
Hemos usado esta métrica ya que según la docmentación de la librería \cite{b2} es la recomendada para valores enteros.
\\
\item Distancia \emph{Manhattan} para el dataset con atributos relacionales:
\begin{equation}
d(\textbf{x},\textbf{x}') = \sum_{i=1}^n |x_{i} - x_{i}'|
\end{equation}
En este caso es la adecuada al tratarse de valores numéricos reales.
\end{itemize}

Para el cálculo del modelo ha sido necesaria la clase neighbors de la librería sklearn.
Por último, una vez se ha construido el modelo lo evaluamos mediante validación cruzada (cross validation) con 10 pliegues. Se divide el dataset según el numero de pliegues, siendo uno de estos el que se usará para probar el modelo y el resto para entrenarlo, de tal manera que cada pliegue acabe siendo usado como subconjunto de prueba. Cada una de estas iteraciones dará como resultado una tasa de acierto, la media de estas será el valor asociado a cada k. Finalmente se comparan y se escoge el valor de k que obtuviera la media la más alta.

\subsection{Naive Bayes}
Naive Bayes se trata de un modelo de clasificación paramétrico, ya que no depende de la cantidad de ejemplos que contega el conjunto de entrenamiento. Los valores deben ser discretos, y en caso contrario deberán someterse a un proceso de discretización, donde se divide el rango de los valores de los atributos en subintervalos, los cuales constituiran los posibles valores de la variable discretizada. En nuestro era necesaria la discretización al tratarse de enteros con una gran diferencia entre los valores.
Para realizar la tarea de clasificación se aprende primero los siguientes valores de los parámetros:
\begin{itemize}
\item La probabilidad de cada clase c:
\begin{equation}
\mathbbm{P}(c) = \frac{ N_{c}}{N}
\end{equation}
Donde $N_{c}$ es la cantidad total de ejemplos que pertenecen a la clase c, y N la cantidad total de los ejemplos que hay en el conjunto de entrenamiento.
\\ 
\item La probabilidad de para cada atributo X, cada posible valor de x el atributo y cada clase c:
\begin{equation}
\mathbbm{P}(X = x | c) = \frac{N_{X=x,c}}{N{c}}
\end{equation}
Donde $N_{X=x,c}$  es la cantidad total de ejemplos del conjunto de entrenamiento que pertenecen a la clase c en los que el atributo X toma el valor x.
\end{itemize}

A la hora de discretizar los atributos hemos usado KBinsDiscretizer \cite{b3}, de la libretria sklearn. Para los parámetros usamos una codificación one-hot, ya que algunos atributos tiene valores numéricos muy elevados comparados con otros. Por esta razón hemos elgido esta codificación, pues proporciona mejor resultado que otras (como por ejemplo la de tipo ordinal).

A la hora de construir el modelo se ha usado MultinomialNB(alpha=k)  \cite{b4}, pues es el más apropiado para clasificación de atributos numéricos discretizados. El hiperparámetro usado, k, se usa para realizar el suavizado de Laplace. Dicho suavizado se realiza cuando alguna de las probabilidades calculadas para una clase c toma el valor 0, haciendo que un ejemplo nunca se clasifique en dicha clase c. La fórmula que nos indica el suavizado de Laplace es la siguiente:
\begin{equation}
\mathbbm{P}(X = x | c) = \frac{N_{X=x,c}+1}{N_{c} + k|X|}
\end{equation}

Para la evaluación de este modelo también hemos usado el método de validación cruzada con 10 pliegues.

\subsection{Árboles de Decisión}

Los Árboles de Clasificación y regresión (del inglés CART, clasification and regresion tree) son modelos para adecuados para tareas de tanto de clasificación como de regresión dados atributos necesariamente numéricos, ya sean continuos o discretos.En un CART cada nodo interno está etiquetado con un atributo y un valor umbral para dicho atributo, mientras que cada hoja está etiquetada con una clase si es una tarea de clasificación, o un número en caso de que se trate de una tarea de regresión.  Dado nuestro conjunto de datos, la tarea a abordar es una de clasificación, por lo que elegimos el tipo de árbol correspondiente.

El algoritmo CART para el aprendizaje del modelo es tal que dado un conjunto de ejemplos de entrenamiento $\mathscr{D}$, denotamos  $\mathscr{D}_n$ al subconjunto de ejemplos que satisfacen  todas las condiciones de los nodos desde la raíz hasta hasta n. Dado un nodo $n$ un atributo $X$, siendo $x_1$, $x_2$, ... , $x_k$  la secuencia de distintos valores que toma $X$ en $\mathscr{D}_n$, estando estos ordenados de menor a mayor. Siendo $u_i = \frac{(x_i + x_{i+1})}{2} $ el umbral candidato para $X$ y con $i$ en el rango $(1, 2, ..., k-1)$. A continuación se divide  $\mathscr{D}_n$ según el umbral. Si los ejemplos de $X$ toman un valor menor o igual que $u$ estos se agrupan en  $\mathscr{D}_n^{Izq}$, mientras que si son mayores que $u$ se agruparan en en el subconjunto $\mathscr{D}_n^{Der}$. Por último, se hace uso de una función $I$ que permite medir la impureza de un conjunto de ejemplos, para poder elegir el par $(X, u)$ que nos de una mejor partición de  $\mathscr{D}_n$, siendo dicha función:

\begin{equation}
\textbf{arg mín  } \frac{|\mathscr{D}_{n}^{Izq}|}{|\mathscr{D}|}I(\mathscr{D}_{n}^{Izq})+ \frac{|\mathscr{D}_{n}^{Der}|}{|\mathscr{D}|}I(\mathscr{D}_{n}^{Der})
\end{equation}


\begin{figure} % opción de posicionamiento
    \centering
    \includegraphics[width=0.5\textwidth]{./ImagenesMemoria/Arbol}
    \caption{\label{fig:arbolDecision}Árbol de Decisión}
\end{figure}

Una representación del algoritmo sería:

\begin{pseudo}*
    \hd{CART}(\mathscr{D}) \\
    \textbf{Si} \textnormal{\fn{NODIVISIBLE($\mathscr{D}$)}} \textbf{entonces} \\+
    \textbf{Devolver} \textnormal{un nodo etiquetado con \fn{ETIQUETA}(\mathscr{D})} \\-
    Si no entonces \\+
    \(\textnormal{Elegir el par $(X, u)$ que proporcione la mejor} \) \\+
    \(\textnormal{partición $(\mathscr{D}^{Izq},\mathscr{D}^{Der})$ de $\mathscr{D}$}\) \\-
    \( T_{1} \leftarrow \textnormal{CART($\mathscr{D}^{Izq}$)}\) \\
    \( T_{2} \leftarrow \textnormal{CART($\mathscr{D}^{Der}$)}\) \\
    \(\textbf{Devolver } \textnormal{un nodo etiquetado con ($X, u$) y cuyos}\)\\+
    \(\textnormal{hijos sean $T_{1}$  y $T_{2}$}\)\\-
 \end{pseudo}





 La función de impureza usada para una tarea de clasificación suele serel índice de Gini, pues estima la probabilidad de clasificar incorrectamente un ejemplo. Tal que: 
\begin{equation}
G(\mathscr{D}) = \sum_{c\in C} \hat{\pi}_c (1-  \hat{\pi}_c) = 1 -  \sum_{c\in C}  \hat{\pi}_c^2
\end{equation}

Para abordar esta tarea hemos hecho uso de las librerías sklearn y matplotlib para mostrar el árbol resultado por pantalla. Dada la naturaleza hemos decidido usar la función DecisionTreeClassifier de la clase tree, puesto que nos proporciona un árbol de decisión el cual ha sido limitado a una profundidad máxima de 5. Para terminar, realizamos una evaluación del modelo mediante el método score, que calcula el rendimiento del modelo, dados por separado el conjunto de ejemplos de prueba y la clase de cada uno de estos ejemplos.


\subsection{Redes Neuronales}

Las Redes Neuronales son un modelo de predicción inspirado en el funcionamiento del cerebro, permitiendo que programas informáticos reconozcan patrones y resuelvan problemas comunes en el campo de la Inteligencia Artificial, Aprendizaje Automático y Aprendizaje Profundo. Son un conjunto de neuronas artificiales, cada una ellas con un sesgo y un peso asociado e interconectadas entre sí. Se agrupan en forma de capas, una de entrada donde se reciben los datos del problema, una o varias capas ocultas y una de salida para dar la predicción según los datos introducidos. Una neurona mandará información a otra neurona de la siguiente capa si la salida de esta es superior al valor del sesgo, si no, no transmitirá informacion alguna.

A la hora de entrenar el modelo se le asginarán unos valores aleatorios a los pesos de cada neurona, el peso se irá actualizando en función del siguiente algoritmo:

\begin{pseudo}*
    \\
    \textbf{\textnormal{Inicializar los pesos aleatoriamente}} \\
    \textbf{Repetir}\textnormal{ hasta que se cumpla la condición de terminación: }\\+
    \textbf{Para cada}\textnormal{ ejemplo de entrenamiento}\\+
    \textbf{Si} \textnormal{la salida del perceptrón es incorrecta entonces}\\+
         \textnormal{Actualizar los pesos}\\---
    \textbf{Devolver}\textnormal{ los pesos}\\
 \end{pseudo}

Cuando en el bucle del algoritmo se han considerado todos los ejemplos se dice que ha transcurrido una época.

En nuestro caso (fíjese en la Fig. \ref{fig:red}), tenemos una capa de entrada de 3 neuronas, correspondientes a cada uno de los atributos usados para calcular el objetivo. Para la capa oculta hemos optado por un total de 10 neuronas con función de activación rectificador (ReLU). Al tratarse de un problema de clasificación binaria, la última capa de nuestra red neuronal estará compuesta por una neurona con funcion de activación sigmoide, ya que los valores de salida oscilarán entre 0 y 1. Finalmente el algoritmo nos dará una tasa de aciertos, cada usuario será clasificado como Partner (1) si esta es mayor que 0.5.

Para el entrenamiento de la Red Neuronal usamos la entropía cruzada binaria como funcion de coste  y el método de descenso por el gradiente (SGD, Stochastic Gradient Descent) para actualizar los pesos en la direccion $-\nabla C$.

· \emph{Binary Crossentropy}:
\begin{equation}
 -y log_e(a^L) - (1-y) log_e(1 - a^L)
\end{equation}

\begin{figure}
    \centering
    \includegraphics[width=0.4\textwidth]{./ImagenesMemoria/RedNeuronal}
    \caption{\label{fig:red}Nuestra Red Neuronal}
\end{figure}

Para la evaluación del modelo hemos dividido los datos en dos subconjuntos de prueba y entrenamiento en un 25\% y un 75\% respectivamente, aportándonos unos resultados con un rendimiento excelente.


\section{Resultados}


En esta sección se detallarán tanto los experimentos realizados como los
resultados conseguidos. Para poder medir el rendimiento de los modelos mediante un solo elemento, realizamos la media de los resultados obtenidos en validación cruzada, y usamos dicha media para comparar con el resto de modelos.

\subsection{KNN}
El único contratiempo que nos encontramos a la hora de evaluar el modelo, fue que al repasar nuestro trabajo, observamos que al realizar el algoritmo KNN, a penas se tenía en cuenta el atributo mature con respecto a views, ya que toma valores mucho mas elevados, haciendo necesario una normalización de los atributos.

 El mejor resultado obtenido al aplicar validación cruzada al modelo sin atributos relacionales es: $0.946$, con el hiperparametro $k = 10$.  Al añadir los atributos relacionales la mejor tasa de acierto sigue siendo para $k = 10$, aunque el valor aumenta a: $0.958$.

Como ya se ha mencionado, para comparar los resultados se hace uso de la media de las tasa de aciertos. Sin atributos relacionales la media da : $0.934$, mientras que con relacionales aumenta a : $0.955$. Podemos concluir entonces, que el añadir los atributos relacionales mejoran el redimiento del modelo KNN.

\subsection{Naive Bayes}
En este caso, estabamos bastante familiarizados con la realización del modelo gracias a las clases prácticas. Lo único que tuvimos que investigar (meidante la documentación de sklearn) fue el proceso de discretización, como ya hemos mencionado anteriormente.

 El mejor resultado obtenido al aplicar validación cruzada al modelo sin atributos relacionales es: $0.952$, con el hiperparametro $k = 1$.  Al añadir los atributos relacionales la mejor tasa de acierto sigue siendo para $k = 1$, aunque el valor aumenta a: $0.957$.

Como ya se ha mencionado, para comparar los resultados se hace uso de la media de las tasa de aciertos. Sin atributos relacionales la media da : $0.949$, mientras que con relacionales aumenta a : $0.955$. Podemos concluir entonces, que el añadir los atributos relacionales mejoran el redimiento del modelo Naive Bayes.


\subsection{Árbol de Decisión}


Para árboles tenemos el método $score$ de sklearn que nos permite calcular el rendimiento del modelo mediante un solo valor, siendo el resultado devuelto por este método el que usaremos para la evaluación del modelo. 

Sin atributos relacionales la tasa de acierto devuelta es: $0.981$. Se puede observar que debido al peso de los otros atributos el algoritmo se tiene menos en cuenta el atributo mature. En cambio, al añadir los atributos relacionales el árbol cambia de forma drástica, pues ahora el algoritmo tiene en cuenta tanto los atributos relacionales como el atributo mature. No obstante esto empeora el rendimiento del modelo, pues la tasa de acierto baja: $0.980$.

 Podemos concluir entonces, que el añadir los atributos relacionales empeoran el redimiento del modelo Árbol de Decisión.

\subsection{Redes Neuronales}

A la hora de realizar este modelo no tuvimos problema en cuanto al código (no más que alguna revisión a la documentación de las librerías), gracias a la los ejemplos dados en clase práctica. Sin embargo, para el comprensión del algoritmo, las estructuras de las capas o la función de pérdida, tuvimos que apoyarnos en el temario de la asignatura.

Durante el entrenamiento de la red, la función de pérdida (binary cross-entropy) disminuye hasta: $0.631$, y la tasa de acierto aumenta hasta: $0.947$, al haber transcurrido 10 épocas. Evaluando con los atributos y objetivos de prueba, separados anteriormente, nos da un valor de la función de pérdida de: $0.353$ y de tasa de acierto de: $0.942$. Al añadir los atributos relacionales, y usando el mismo número de épocas, en el entrenamiento la función de pérdida disminuye hasta: $0.447$ y la tasa de acierto aumenta hasta: $0.945$. En la evaluación, con los atributos y objetivos de prueba la función de pérdida da una valor de: $0.438$ y un valor para la tasa de acierto de: $0.946$.  

Como se puede observar, la tasa de acierto de la evaluación realizada aumenta ligeramente al añadir los atributos relacionales.

\subsection{Comparación de los modelos}

Hemos seleccionado por tanto el modelo de \textbf{Árboles de Decisión}, pues a pesar de que a añadir los atributos relacionales, baje la tasa de acierto, esta sigue siendo mayor que la obtenida con el resto de modelos que hemos probado. Es digno de mención que el modelo que más ha mejorado el rendimiento con la adicción de los atributos relacionales es KNN, pues la media de las tasas de acierto aumenta en un: $0.021$.








\section{Conclusiones}



Este trabajo nos ha resultado muy útil para repasar la teoría de los modelos de aprendizaje automático y aclarar conceptos clave de redes neuronales, al ser este un tema bastante más complejo que el resto de modelos. A medida que hemos ido realizando el trabajo, nuestro conocimiento del mismo ha mejorado, a base de construir y comprender los distintos modelos usados. 

Si bien al principio nos abrumaba el uso y estructura de la herramienta \LaTeX, a medida que le hemos dado uso nos hemos ido familiarizando con la herramienta, provocando así una mayor soltura al darle uso, o incluso resultando entretenido. Esto nos será de gran ayuda para trabajos futuros, ya sean en la carrera o fuera de ella.



También nos has sorprendido lo fácil que nos ha resultado volver a manejar python con facilidad, pues llevabamos sin usar python en la carrera desde el primer curso. Esto ha sido gracias a los apuntes que se nos proporciona en la página de la asignatura.

Para el control de versiones y trabajo simultáneo nos hemos apoyado en la herramienta github. Dicha herramienta nos ha facilitado la cooperación y comunicación, evitando así tener que hacer reuniones frecuentes, ahorrandonos tiempo de planificación. 

En cuanto a las librerías usadas, nos han servido mucho para expandir nuestro conocimiento sobre librerías orientadas a la inteligencia artificial y dominar su uso. Iguialmente ha resultado muy útil para aprender y familiarizarnos con la lectura y comprensión la documentación de cualquier librería.\\



\begin{thebibliography}{00}
\bibitem{b1} \url{https://scikit-learn.org/stable/modules/preprocessing.html#normalization}
\bibitem{b2} \url{https://scikit-learn.org/stable/modules/generated/sklearn.metrics.DistanceMetric.html}
\bibitem{b3} \url{https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KBinsDiscretizer.html}
\bibitem{b4} \url{https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html}
\bibitem{b5} \url{https://scikit-learn.org/stable/modules/naive_bayes.html}
\bibitem{b6} \url{https://www.ibm.com/cloud/learn/neural-networks}
\bibitem{b7} \url{https://www.draw.io}
\bibitem{b8} \url{https://scikit-learn.org/stable/modules/tree.html }
\bibitem{b9} \url{https://machinelearningmastery.com/binary-classification-tutorial-with-the-keras-deep-learning-library/ }
\bibitem{b10} \url{https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/}
\bibitem{b11} Apuntes de la asignatura Inteligencia Artificial, Universidad de Sevilla (2021-2022)



\end{thebibliography}


\end{document}
